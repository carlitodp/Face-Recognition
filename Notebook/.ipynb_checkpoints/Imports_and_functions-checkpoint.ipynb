{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1519cd64-ac42-467b-ac83-d5063279500f",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76db593a-5c3d-4ab2-899a-9de8d3d14449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "8\n",
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.sysconfig.get_build_info()[\"cudnn_version\"])\n",
    "print(tf.keras.__version__)\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import resnet, mobilenet, vgg19, convnext, efficientnet, efficientnet_v2, mobilenet_v2, mobilenet_v3, MobileNetV3Large, MobileNetV3Small, inception_resnet_v2, resnet_v2\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD \n",
    "from tensorflow.keras.losses import BinaryCrossentropy, CosineSimilarity\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.initializers import HeNormal, GlorotUniform\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as a\n",
    "import logging\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from google_images_download import google_images_download\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "208a9210-4cac-4b7b-b518-b1d9a3600861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729082744.836199  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082744.898806  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082744.898882  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082744.902078  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082744.902156  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082744.902190  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082745.081542  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729082745.081655  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-16 07:45:45.081668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729082745.081740  255677 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-16 07:45:45.081801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01afee54-71ad-4e41-8718-aabc75f55915",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9cc18-911d-4ebb-816b-e39f88b0a059",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5582cf-f370-4779-8255-19c7a6d32775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset_gen, image_shape, set, batch_size, buffer_size):\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "    dataset_gen,\n",
    "    output_signature=(\n",
    "        (\n",
    "            tf.TensorSpec(shape=image_shape, dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=image_shape, dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.float32)\n",
    "    )\n",
    ")\n",
    "    \n",
    "\n",
    "    dataset.cache(f\"/mnt/e/cached_data/cached_data_{set}\")\n",
    "    \n",
    "    if set == \"train\":\n",
    "        print(\"dataset shuffled\")\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2b5ea-cd3c-4f93-9877-91950d49154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_triplet_string(data_path):\n",
    "\n",
    "    celeb_list = os.listdir(data_path)\n",
    "    celeb_anchor = random.choice(celeb_list)\n",
    "    celeb_anchor_image_list = glob.glob(os.path.join(data_path, celeb_anchor,\"*.jpg\"))\n",
    "    anchor = random.choice(celeb_anchor_image_list)\n",
    "    positif = pick_random_excluding(celeb_anchor_image_list,anchor)\n",
    "\n",
    "    celeb_negatif = pick_random_excluding(celeb_list,celeb_anchor)\n",
    "    celeb_negatif_image_list = glob.glob(os.path.join(data_path, celeb_negatif,\"*.jpg\"))\n",
    "    negatif = random.choice(celeb_negatif_image_list)\n",
    "    \n",
    "    return anchor, positif, negatif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82459f-7d6d-4fd6-9de5-bfa10e9fbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "def check_for_nans_and_infs(tensor, tensor_name):\n",
    "    \"\"\"\n",
    "    Check for NaNs or Infs in a tensor and log the result.\n",
    "    \n",
    "    Args:\n",
    "        tensor (tf.Tensor): The tensor to check.\n",
    "        tensor_name (str): The name of the tensor for error reporting.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check for NaNs or Infs\n",
    "        tf.debugging.check_numerics(tensor, message=f\"{tensor_name} contains NaNs or Infs\")\n",
    "        logging.info(f\"{tensor_name}: No NaNs or Infs found.\")\n",
    "    except tf.errors.InvalidArgumentError as e:\n",
    "        logging.error(f\"{tensor_name}: {e}\")\n",
    "\n",
    "def check_dataset_for_nans_and_infs(dataset, num_batches=None):\n",
    "    \"\"\"\n",
    "    Check a TensorFlow dataset for NaNs or Infs across all batches.\n",
    "    \n",
    "    Args:\n",
    "        dataset (tf.data.Dataset): The dataset to check.\n",
    "        num_batches (int, optional): The number of batches to check. If None, check all batches.\n",
    "    \"\"\"\n",
    "    for i, (images, labels) in enumerate(dataset):\n",
    "        logging.info(f\"Checking batch {i}...\")\n",
    "        # Check images and labels\n",
    "        check_for_nans_and_infs(images, f\"Batch {i} images\")\n",
    "        check_for_nans_and_infs(labels, f\"Batch {i} labels\")\n",
    "        \n",
    "        # Stop after checking the specified number of batches (if given)\n",
    "        if num_batches is not None and i >= num_batches - 1:\n",
    "            logging.info(f\"Checked {num_batches} batches, stopping.\")\n",
    "            break\n",
    "        elif num_batches is None and i % 10 == 0:\n",
    "            logging.info(f\"Checked {i + 1} batches so far...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc37cd3-6749-40ea-b3cf-6adb4d9d6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_double_neg(folder_name, round_per_image, set, save_data, id, count_per_image):\n",
    "\n",
    "    dataset_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/{folder_name}\"\n",
    "    celeb_list = os.listdir(dataset_path)\n",
    "    \n",
    "    first_image = []\n",
    "    second_image = []\n",
    "    double = []\n",
    "    \n",
    "    for celeb in celeb_list:\n",
    "        image_celeb_list = glob.glob(os.path.join(dataset_path, celeb,\"*.jpg\"))\n",
    "        \n",
    "        i = 0\n",
    "        for image_celeb in image_celeb_list:\n",
    "            \n",
    "            while i < count_per_image :\n",
    "                \n",
    "                if set == \"train\":\n",
    "                    for round in range(0,round_per_image):\n",
    "                        first_image.append(image_celeb)\n",
    "                        celeb_neg = pick_random_excluding(celeb_list,celeb)\n",
    "                        image_celeb_neg_list = glob.glob(os.path.join(dataset_path, celeb_neg,\"*.jpg\"))\n",
    "                        second_image.append(pick_random_excluding(image_celeb_neg_list,image_celeb))\n",
    "                else:\n",
    "                    first_image.append(image_celeb)\n",
    "                    celeb_neg = pick_random_excluding(celeb_list,celeb)\n",
    "                    image_celeb_neg_list = glob.glob(os.path.join(dataset_path, celeb_neg,\"*.jpg\"))\n",
    "                    second_image.append(pick_random_excluding(image_celeb_neg_list,image_celeb))\n",
    "                    \n",
    "                i = i + 1\n",
    "                \n",
    "    for i in range(0,len(first_image)):\n",
    "        double.append([first_image[i], second_image[i]])\n",
    "\n",
    "    if save_data:\n",
    "        now = id.strftime(\"%Y_%m_%d_%M_%S\")\n",
    "        for i in range(0, len(double)):\n",
    "            doublet = double[i]\n",
    "            im_1 = doublet[0]\n",
    "            im_2 = doublet[1]\n",
    "            \n",
    "            save_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{now}/{set}/neg/{i}\"\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "            shutil.copy(im_1, os.path.join(save_path, os.path.basename(im_1)))\n",
    "            shutil.copy(im_2, os.path.join(save_path, os.path.basename(im_2)))\n",
    "\n",
    "    return tf.convert_to_tensor(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f70fef-8b70-47e2-b246-c7167ad66498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_double_pos(folder_name, round_per_image, set, save_data, id, count_per_image):\n",
    "\n",
    "    dataset_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/{folder_name}\"\n",
    "    celeb_list = os.listdir(dataset_path)\n",
    "    \n",
    "    first_image = []\n",
    "    second_image = []\n",
    "    double = []\n",
    "    \n",
    "    for celeb in celeb_list:\n",
    "        image_celeb_list = glob.glob(os.path.join(dataset_path, celeb,\"*.jpg\"))\n",
    "\n",
    "        i = 0\n",
    "        for image_celeb in image_celeb_list:\n",
    "            while i < count_per_image :\n",
    "                \n",
    "                if set == \"train\":\n",
    "                    for round in range(0,round_per_image):\n",
    "                        first_image.append(image_celeb)\n",
    "                        second_image.append(pick_random_excluding(image_celeb_list,image_celeb))\n",
    "                else:\n",
    "                    first_image.append(image_celeb)\n",
    "                    second_image.append(pick_random_excluding(image_celeb_list,image_celeb))\n",
    "                i = i + 1\n",
    "    \n",
    "    for i in range(0,len(first_image)):\n",
    "        double.append([first_image[i], second_image[i]])\n",
    "    \n",
    "    if save_data:\n",
    "        now = id.strftime(\"%Y_%m_%d_%M_%S\")\n",
    "        for i in range(0, len(double)):\n",
    "            doublet = double[i]\n",
    "            im_1 = doublet[0]\n",
    "            im_2 = doublet[1]\n",
    "            \n",
    "            save_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{now}/{set}/pos/{i}\"\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "            shutil.copy(im_1, os.path.join(save_path, os.path.basename(im_1)))\n",
    "            shutil.copy(im_2, os.path.join(save_path, os.path.basename(im_2)))\n",
    "\n",
    "    return tf.convert_to_tensor(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f6978-2f5f-4216-90b6-09ff25e699c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_distance(tensors):\n",
    "    x, y = tensors\n",
    "    return tf.reduce_sum(tf.abs(x - y), axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc551d8-91fd-446c-8a22-ad8eedf50fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_valid():\n",
    "    for double_v,y_v in zip(doubles_valid,ys_valid):      \n",
    "        yield (process_file(double_v[0], image_shape), process_file(double_v[1], image_shape)), y_v "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c6fb6-1bdc-435a-97a2-db1ea8626735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_train():\n",
    "    for double,y in zip(doubles_train,ys_train):      \n",
    "        yield (process_file(double[0], image_shape), process_file(double[1], image_shape)), y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a43fb3-1277-494e-9c1b-a150fbbeb74e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ead99250-130e-45fe-83de-273576916d93",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77252d-edc2-41db-b504-65653a9e772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    transform = a.Compose([\n",
    "        # Color Augmentations\n",
    "        a.RandomBrightnessContrast(p=0.5),  # Random brightness and contrast adjustments\n",
    "        a.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5),  # Adjust hue and saturation\n",
    "\n",
    "        # Spatial Augmentations\n",
    "        a.HorizontalFlip(p=0.5),  # Flip horizontally\n",
    "        a.Rotate(limit=15, p=0.5),  # Small rotations (up to 15 degrees)\n",
    "        a.GaussianBlur(blur_limit=(3, 7), p=0.2),  # Apply Gaussian blur\n",
    "\n",
    "        # Size Adjustments\n",
    "        a.PadIfNeeded(min_height=64, min_width=64, border_mode=0),  # Ensure minimum size\n",
    "        a.Resize(height=64, width=64),  # Resize to ensure the correct input size\n",
    "\n",
    "        # Normalization (Optional but Recommended)\n",
    "        # a.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5), always_apply=True),\n",
    "    ])\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0155d86a-476b-4194-b171-65c846ba6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def process_file(file_path, image_shape):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    img.set_shape([None, None, 3])\n",
    "    img = tf.image.rgb_to_grayscale(img) if image_shape[-1] == 1 else img\n",
    "    img = tf.image.resize(img, (image_shape[0], image_shape[1]))\n",
    "    img = tf.ensure_shape(img, image_shape)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03de247e-1a39-4264-b55c-862158a1ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_images(image_paths, label, image_shape):\n",
    "    # Process both images from the pair\n",
    "    image1 = process_file(image_paths[0], image_shape)\n",
    "    image2 = process_file(image_paths[1], image_shape)\n",
    "    return (image1, image2), label  # Return as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d90799-3891-432a-a7d7-370142d0849e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_v2(doubles, ys, image_shape, set, batch_size, buffer_size):\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((doubles, ys))\n",
    "    dataset = dataset.map(lambda paths, label: load_and_preprocess_images(paths, label, image_shape))\n",
    "\n",
    "    # dataset.cache(f\"/mnt/e/cached_data/cached_data_{set}\")\n",
    "    \n",
    "    if set == \"train\":\n",
    "        print(\"dataset shuffled\")\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "        \n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b0c486-7cab-4e28-8e75-9c87665a1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images_data(folder_name):\n",
    "\n",
    "    dataset_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/{folder_name}/\"\n",
    "    celeb_list = os.listdir(dataset_path)\n",
    "    dic = {}\n",
    "    for celeb in celeb_list:\n",
    "        image_dir = os.path.join(dataset_path,celeb)\n",
    "        image_list = glob.glob(os.path.join(image_dir,\"*.jpg\"))\n",
    "        dic[celeb] = len(image_list)\n",
    "    \n",
    "    print(f\"The min number of images per folder is {min(dic.values())}\")\n",
    "    print(\"\")\n",
    "    print(f\"The max number of images per folder is {max(dic.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd694ab-34fa-4ff8-abcf-2648f6ae95dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distance_embbedding(anchor, positif, negatif, embedding_model, distance_calculation):\n",
    "\n",
    "    anchor = tf.convert_to_tensor(anchor, dtype=tf.string).numpy()\n",
    "    positif = tf.convert_to_tensor(positif, dtype=tf.string).numpy()\n",
    "    negatif = tf.convert_to_tensor(negatif, dtype=tf.string).numpy()\n",
    "    \n",
    "    anchor = process_file(anchor, image_shape)\n",
    "    positif = process_file(positif, image_shape)\n",
    "    negatif = process_file(negatif, image_shape)\n",
    "    \n",
    "    anchor = tf.expand_dims(anchor, axis=0)\n",
    "    positif = tf.expand_dims(positif, axis=0)\n",
    "    negatif = tf.expand_dims(negatif, axis=0)\n",
    "\n",
    "    embedding_model(anchor).numpy()\n",
    "    embedding_model(positif).numpy()\n",
    "    embedding_model(negatif).numpy()\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Plot anchor and positive side by side in the first row\n",
    "    plt.subplot(2, 2, 1)  # 2 rows, 2 columns, position 1\n",
    "    plt.imshow(tf.squeeze(anchor,axis=0), cmap='gray')\n",
    "    plt.title(\"Anchor\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)  # 2 rows, 2 columns, position 2\n",
    "    plt.imshow(tf.squeeze(positif,axis=0), cmap='gray')\n",
    "    plt.title(\"Positive\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Plot anchor and negative side by side in the second row\n",
    "    plt.subplot(2, 2, 3)  # 2 rows, 2 columns, position 3\n",
    "    plt.imshow(tf.squeeze(anchor,axis=0), cmap='gray')\n",
    "    plt.title(\"Anchor\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)  # 2 rows, 2 columns, position 4\n",
    "    plt.imshow(tf.squeeze(negatif,axis=0), cmap='gray')\n",
    "    plt.title(\"Negative\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    distance_ap = distance_calculation([anchor, positif]).numpy()\n",
    "    print(f\"Distance between the anchor and the positif is {distance_ap}\")\n",
    "\n",
    "    distance_an = distance_calculation([anchor, negatif]).numpy()\n",
    "    print(f\"Distance between the anchor and the negatif is {distance_an}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57196a12-8a65-4927-a636-fe7a321d4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_excluding(input_list, exclude_value):\n",
    "    # Filter the list to exclude the specified value\n",
    "    filtered_list = [item for item in input_list if str(item) != exclude_value]\n",
    "    \n",
    "    # Check if the filtered list is not empty\n",
    "    if not filtered_list:\n",
    "        raise ValueError(\"No valid numbers available in the list after exclusion.\")\n",
    "    \n",
    "    # Pick a random element from the filtered list\n",
    "    return random.choice(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cf412-f121-4600-994e-7c7cf424dfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_from_dir(dataset_folder, set):\n",
    "\n",
    "    root = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{dataset_folder}/\"\n",
    "\n",
    "    double_p = []\n",
    "    double_n = []\n",
    "\n",
    "    classes = [\"pos\", \"neg\"]\n",
    "\n",
    "    for class_ in classes :\n",
    "        set_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{dataset_folder}/{set}/{class_}\"\n",
    "        doubles = os.listdir(set_path)\n",
    "\n",
    "        for double in doubles :\n",
    "            \n",
    "            pair = glob.glob(os.path.join(set_path, double, \"*.jpg\"))\n",
    "            \n",
    "            if len(pair)!=2 :\n",
    "                print(double, class_)\n",
    "            \n",
    "            if class_ == \"pos\":\n",
    "                double_p.append(pair)\n",
    "            else: \n",
    "                double_n.append(pair)\n",
    "\n",
    "    return tf.convert_to_tensor(double_p), tf.convert_to_tensor(double_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577fb8a1-2642-4352-9c77-0971ae842a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_double_pos_v2(folder_name, set_, save_data, id, count_per_image, apply_augmentation):\n",
    "\n",
    "    dataset_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/{folder_name}\"\n",
    "    celeb_list = os.listdir(dataset_path)\n",
    "    \n",
    "    first_image = []\n",
    "    second_image = []\n",
    "    double = []\n",
    "\n",
    "    for celeb in celeb_list:\n",
    "        \n",
    "        count = 0\n",
    "        image_celeb_list = glob.glob(os.path.join(dataset_path, celeb,\"*.jpg\"))\n",
    "        \n",
    "        while count < count_per_image :\n",
    "            \n",
    "            image_1 = random.choice(image_celeb_list)\n",
    "            image_2 = pick_random_excluding(image_celeb_list,image_1)\n",
    "            \n",
    "            first_image.append(image_1)\n",
    "            second_image.append(image_2)\n",
    "\n",
    "            count = count + 1\n",
    "\n",
    "    for i in range(0,len(first_image)):\n",
    "        double.append((first_image[i], second_image[i]))\n",
    "\n",
    "    double = list(set(double))\n",
    "    double = [list(pair) for pair in double]\n",
    "    \n",
    "    if save_data:\n",
    "        print(\"saving data\")\n",
    "        now = id.strftime(\"%Y_%m_%d_%M_%S\")\n",
    "        for i in range(0, len(double)):\n",
    "            doublet = double[i]\n",
    "            im_1 = doublet[0]\n",
    "            im_2 = doublet[1]\n",
    "            \n",
    "            save_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{now}/{set_}/pos/{i}\"\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "            shutil.copy(im_1, os.path.join(save_path, os.path.basename(im_1)))\n",
    "            shutil.copy(im_2, os.path.join(save_path, os.path.basename(im_2)))\n",
    "            \n",
    "    if apply_augmentation:\n",
    "             augment_data(f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{now}/{set_}/pos/\")\n",
    "\n",
    "    return tf.convert_to_tensor(double)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841be721-74cf-4174-bf89-e4b9e88f1651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_double_neg_v2(folder_name, set_, save_data, id, count_per_image, apply_augmentation):\n",
    "\n",
    "    dataset_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/{folder_name}\"\n",
    "    celeb_list = os.listdir(dataset_path)\n",
    "    \n",
    "    first_image = []\n",
    "    second_image = []\n",
    "    double = []\n",
    "    \n",
    "    for celeb in celeb_list:\n",
    "\n",
    "        count = 0\n",
    "        image_celeb_list = glob.glob(os.path.join(dataset_path, celeb,\"*.jpg\"))\n",
    "\n",
    "        while count < count_per_image :\n",
    "            \n",
    "            first_image.append(random.choice(image_celeb_list))\n",
    "            celeb_neg = pick_random_excluding(celeb_list,celeb)\n",
    "            image_celeb_neg_list = glob.glob(os.path.join(dataset_path, celeb_neg,\"*.jpg\"))\n",
    "            second_image.append(random.choice(image_celeb_neg_list))\n",
    "\n",
    "            count = count+1\n",
    "                \n",
    "    for i in range(0,len(first_image)):\n",
    "        double.append((first_image[i], second_image[i]))\n",
    "        \n",
    "    double = list(set(double))\n",
    "    double = [list(pair) for pair in double]\n",
    "\n",
    "    if save_data:\n",
    "        print(\"saving data\")\n",
    "        now = id.strftime(\"%Y_%m_%d_%M_%S\")\n",
    "        for i in range(0, len(double)):\n",
    "            doublet = double[i]\n",
    "            im_1 = doublet[0]\n",
    "            im_2 = doublet[1]\n",
    "            \n",
    "            save_path = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{now}/{set_}/neg/{i}\"\n",
    "            os.makedirs(save_path)\n",
    "            \n",
    "            shutil.copy(im_1, os.path.join(save_path, os.path.basename(im_1)))\n",
    "            shutil.copy(im_2, os.path.join(save_path, os.path.basename(im_2)))\n",
    "\n",
    "        if apply_augmentation:\n",
    "             augment_data(f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/training_dataset/{now}/{set_}/neg/\")\n",
    "\n",
    "    return tf.convert_to_tensor(double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd53d488-a45b-4df2-8164-3aecfd74f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_eff_shuffling(tensor1, tensor2):\n",
    "    perm = tf.random.shuffle(tf.range(tf.shape(tensor1)[0]))\n",
    "    tensor1 = tf.gather(tensor1, perm)\n",
    "    tensor2 = tf.gather(tensor2, perm)\n",
    "\n",
    "    return tensor1, tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a0f1b5-1838-444e-bfa5-1990dad8573d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowRandomDoublet(dataset, number_of_batches):\n",
    "    # Define the number of doublets per batch\n",
    "    doublets_per_batch = 32\n",
    "    total_doublets = doublets_per_batch * number_of_batches\n",
    "    \n",
    "    # Create a figure with appropriate size\n",
    "    fig, axes = plt.subplots(nrows=total_doublets, ncols=2, figsize=(15, 5 * total_doublets))\n",
    "    \n",
    "    if total_doublets == 1:\n",
    "        axes = [axes]  # Handle the case where there's only one doublet\n",
    "    \n",
    "    count = 0  # To keep track of the doublets plotted\n",
    "    \n",
    "    for element in dataset.take(number_of_batches):\n",
    "        (image1, image2), label = element\n",
    "        \n",
    "        image1_np = image1.numpy()\n",
    "        image2_np = image2.numpy()\n",
    "        labels_np = label.numpy()\n",
    "        \n",
    "        for i in range(len(image1_np)):\n",
    "            if count >= total_doublets:\n",
    "                break\n",
    "            \n",
    "            axes[count, 0].imshow(image1_np[i])\n",
    "            axes[count, 0].axis('off')\n",
    "            axes[count, 1].imshow(image2_np[i])\n",
    "            axes[count, 1].axis('off')\n",
    "            \n",
    "            axes[count, 0].set_title(f\"Label: {labels_np[i]}\")\n",
    "            count += 1\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e3f77c-8abb-4c8b-b16a-dfe93d75f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    x, y = vectors\n",
    "    squared_diff = tf.square(x - y)\n",
    "    sum_squared_diff = tf.reduce_sum(squared_diff, axis=-1, keepdims=True)\n",
    "    distance = tf.sqrt(tf.maximum(sum_squared_diff, 0))\n",
    "    \n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f9182c-6538-4593-9a98-12ee9ade2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(vectors):\n",
    "    x, y = vectors\n",
    "    # Compute cosine similarity\n",
    "    similarity = tf.reduce_sum(tf.multiply(x, y), axis=-1, keepdims=True)\n",
    "    # Compute cosine distance\n",
    "    distance = 1.0 - similarity\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb373b-1f69-47d8-83ce-6eeba2cbcb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vectors):\n",
    "    x, y = vectors\n",
    "\n",
    "    cosine_similarity_loss = CosineSimilarity()\n",
    "    cosine_sim = cosine_similarity_loss(x,y) #CosineSimilarity Normalizes the outputs\n",
    "    distance = 1 - cosine_sim\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c38348-2089-4121-bffe-a2d1972439d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS is O NEG is 1\n",
    "def contrastive_loss(y_true, y_pred, margin=1.5):\n",
    "    positive_loss = (1 - y_true) * tf.square(y_pred)\n",
    "    negative_loss = y_true * tf.square(tf.maximum(0.0, margin - y_pred))\n",
    "    loss = tf.reduce_mean(0.5 * (positive_loss + negative_loss))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a8b48c-17ec-40d2-98c2-2177286c43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def erase_augmented_images(image_list):\n",
    "    for img in image_list:\n",
    "        if \"augmented\" in img:\n",
    "            os.remove(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b4896-1bd3-400c-92b4-c9b7766ef54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_dataset(dataset_directory, clear_previous_augmentations, transform):\n",
    "\n",
    "    celeb_list = os.listdir(dataset_directory)\n",
    "    \n",
    "    for celeb in celeb_list:\n",
    "        \n",
    "        image_list = glob.glob(os.path.join(dataset_directory, celeb, \"*.jpg\"))\n",
    "        if clear_previous_augmentations:\n",
    "            erase_augmented_images(image_list)\n",
    "\n",
    "        for image in image_list:\n",
    "            img = cv2.imread(image)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            transformed_image = transform(image=img)[\"image\"]\n",
    "            transformed_image = cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR)\n",
    "            path = image.replace(\".jpg\", \"_augmented.jpg\")\n",
    "\n",
    "            cv2.imwrite(path, transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a9eba-3e3d-41ea-a5b0-5c7f27867e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(dataset_directory):\n",
    "\n",
    "    pair_folders = os.listdir(dataset_directory)\n",
    "    \n",
    "    for folder in pair_folders:\n",
    "\n",
    "        pair_folders_ = os.listdir(dataset_directory)\n",
    "        \n",
    "        pair_folder = os.path.join(dataset_directory, folder)\n",
    "        augment_choice = random.choice([0,1])\n",
    "        \n",
    "        if augment_choice == 1 :\n",
    "            \n",
    "            images = glob.glob(os.path.join(pair_folder, \"*.jpg\"))\n",
    "            image_choice = random.choice(images)\n",
    "            not_chosen = images[1] if image_choice == images[0] else images[0]\n",
    "\n",
    "            img = cv2.imread(image_choice)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            transform = get_transform()\n",
    "            transformed_image = transform(image=img)[\"image\"]\n",
    "            transformed_image = cv2.cvtColor(transformed_image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            augmented_image_path = image_choice.replace(\".jpg\", \"_augmented.jpg\")\n",
    "\n",
    "            destination_dir = os.path.join(dataset_directory, str(len(pair_folders_) + 1))\n",
    "            os.makedirs(destination_dir)\n",
    "\n",
    "            shutil.copy(not_chosen, os.path.join(destination_dir, os.path.basename(not_chosen)))\n",
    "            cv2.imwrite(os.path.join(destination_dir,os.path.basename(augmented_image_path)), transformed_image)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62508fca-fa02-4b0b-9ac2-38dc2fd9a9e5",
   "metadata": {},
   "source": [
    "## Model Impplementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f14562b-42ec-4b9b-ba0e-6f46804f8963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation_model(image_height=64, image_width=64):\n",
    "    data_augmentation = tf.keras.Sequential([\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),  # 0.1 * 2 * 180 = 36 degrees total\n",
    "        tf.keras.layers.RandomZoom(height_factor=(-0.2, 0.2), width_factor=(-0.2, 0.2)),\n",
    "        tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
    "        tf.keras.layers.RandomContrast(factor=0.3),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.image.random_brightness(x, max_delta=0.3)),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.image.random_saturation(x, lower=0.7, upper=1.3)),\n",
    "        tf.keras.layers.GaussianNoise(0.05),\n",
    "        tf.keras.layers.Resizing(image_height, image_width),\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c8c76d-5907-41d3-b88a-166a4327c936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instanciate_model(base_model, image_shape, apply_reg, reg_weight, apply_dropout, dropout_prob, apply_augmentation, augmentation_model, distance_method, embedding) :\n",
    "\n",
    "    base_model.trainable = True\n",
    "\n",
    "    l2_reg = regularizers.l2(reg_weight) if apply_reg else None\n",
    "\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
    "\n",
    "  \n",
    "    x = tf.keras.layers.Dense(embedding*3, activation = \"relu\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_prob)(x) if apply_dropout else x\n",
    "    x = tf.keras.layers.Dense(embedding*2, activation = \"relu\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Dropout(dropout_prob)(x) if apply_dropout else x\n",
    "    \n",
    "    if apply_reg:\n",
    "        x = tf.keras.layers.Dense(embedding, kernel_initializer=GlorotUniform(), kernel_regularizer=l2_reg)(x) \n",
    "    \n",
    "    else :\n",
    "        x = tf.keras.layers.Dense(embedding, kernel_initializer=GlorotUniform())(x)\n",
    "\n",
    "    if distance_method == \"cosine\":\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=-1))(x)\n",
    "       \n",
    "    model = Model(inputs = base_model.input, outputs = x, name = \"embedding\")\n",
    "    model.summary()\n",
    "\n",
    "    first_embedding_in = tf.keras.Input(shape = image_shape)\n",
    "    second_embedding_in = tf.keras.Input(shape = image_shape)\n",
    "\n",
    "    if apply_augmentation:\n",
    "        first_embedding_in = augmentation_model(first_embedding_in)\n",
    "        second_embedding_in = augmentation_model(second_embedding_in)\n",
    "        \n",
    "    input = [first_embedding_in, second_embedding_in]\n",
    "\n",
    "    first_embedding = model(first_embedding_in)\n",
    "    second_embedding = model(second_embedding_in)\n",
    "\n",
    "    if distance_method == \"cosine\":\n",
    "        distance = tf.keras.layers.Lambda(cosine_distance)([first_embedding, second_embedding])\n",
    "    if distance_method == \"l2\":\n",
    "        distance = tf.keras.layers.Lambda(euclidean_distance)([first_embedding, second_embedding])\n",
    "    \n",
    "    siamese_network = Model(inputs = input, outputs=distance, name = \"siamese_network\")\n",
    "\n",
    "    return siamese_network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bb3dd-6668-4aeb-a7cf-23f112a2bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, dataset, threshold):\n",
    "    correct_predictions = 0\n",
    "    total_pairs = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        # Assuming the dataset is in the form (images1, images2, labels)\n",
    "        (images1, images2), labels = batch\n",
    "        \n",
    "        # Get distances directly from the model\n",
    "        distances = model([images1, images2])\n",
    "        \n",
    "        # Compare distances with threshold (distance < threshold means similar, otherwise dissimilar)\n",
    "        predictions = tf.where(distances < threshold, 0.0, 1.0)\n",
    "        # predictions = tf.expand_dims(predictions, axis=-1)\n",
    "        \n",
    "        # Ensure labels are of type float32\n",
    "        labels = tf.cast(labels, dtype=tf.float32)\n",
    "\n",
    "        # print(f\"Distances: {distances.numpy()}\")\n",
    "        # print(f\"Predictions: {predictions.numpy()}\")\n",
    "        # print(f\"Labels: {labels.numpy()}\")\n",
    "        \n",
    "        # Compare predictions with labels and count correct ones\n",
    "        correct_predictions += tf.reduce_sum(tf.cast(predictions == labels, dtype=tf.float32))\n",
    "        total_pairs += len(labels)\n",
    "    \n",
    "    # Compute accuracy as the percentage of correct predictions\n",
    "    accuracy = correct_predictions / total_pairs\n",
    "    return accuracy.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4818ae5e-0259-4be3-b816-f6a83d0ae4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def custom_accuracy(y_true, y_pred, threshold):\n",
    "\n",
    "    # Classify predictions based on threshold\n",
    "    y_pred_class = tf.where(y_pred < threshold, 0.0, 1.0)\n",
    "\n",
    "    # Calculate total counts of similar and dissimilar pairs\n",
    "    total_similar = tf.reduce_sum(1 - y_true)  # y_true = 0 for similar pairs\n",
    "    total_dissimilar = tf.reduce_sum(y_true)   # y_true = 1 for dissimilar pairs\n",
    "\n",
    "    # Count correct predictions for similar pairs\n",
    "    similar_correct = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_pred_class, 0.0), tf.equal(y_true, 0.0)), tf.float32))\n",
    "\n",
    "    # Count correct predictions for dissimilar pairs\n",
    "    dissimilar_correct = tf.reduce_sum(tf.cast(tf.logical_and(tf.equal(y_pred_class, 1.0), tf.equal(y_true, 1.0)), tf.float32))\n",
    "\n",
    "    # Overall accuracy\n",
    "    correct_predictions = tf.equal(y_true, y_pred_class)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "    return accuracy, similar_correct, dissimilar_correct, total_similar, total_dissimilar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2e3ea-056d-470d-a63f-fd1e2bfb42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def find_batch_sim_metrics(y_true, y_pred, grouping_method):\n",
    "    \n",
    "    # Calculate the mean distance for similar pairs (y_true == 0)\n",
    "    similar_mask = tf.equal(y_true, 0.0)\n",
    "    similar_distances = tf.boolean_mask(y_pred, similar_mask)\n",
    "    \n",
    "    # Calculate the mean distance for dissimilar pairs (y_true == 1)\n",
    "    dissimilar_mask = tf.equal(y_true, 1.0)\n",
    "    dissimilar_distances = tf.boolean_mask(y_pred, dissimilar_mask)\n",
    "\n",
    "    if grouping_method == \"mean\":\n",
    "        grouped_similar_distance = tf.reduce_mean(similar_distances)\n",
    "        grouped_dissimilar_distance = tf.reduce_mean(dissimilar_distances)\n",
    "\n",
    "    if grouping_method == \"median\":\n",
    "        grouped_similar_distance = reduce_median(similar_distances)\n",
    "        grouped_dissimilar_distance = reduce_median(dissimilar_distances)\n",
    "\n",
    "    if grouping_method == \"quartile\":\n",
    "        grouped_similar_distance = reduce_3rd_quartile(similar_distances)\n",
    "        grouped_dissimilar_distance = reduce_3rd_quartile(dissimilar_distances)\n",
    "\n",
    "    return grouped_similar_distance, grouped_dissimilar_distance\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e58e8-36f8-498e-9218-dfe7f7939db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def forward_back_propagation(batch_doublet, y_true, model, loss, optimizer):\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(batch_doublet, training=True)\n",
    "        loss_ = loss(y_true, y_pred)\n",
    "            \n",
    "    grads = tape.gradient(loss_, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "\n",
    "    return loss_, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc38b9d-0321-4d47-911b-7d32fe31b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def reduce_median(tensor):\n",
    "    n = tf.shape(tensor)[0]\n",
    "\n",
    "    # Handle empty tensor case\n",
    "    if n == 0:\n",
    "        tf.print(\"reduce_median called with tensor:\", tensor)\n",
    "        tf.print(\"Warning: Received empty tensor in reduce_median.\")\n",
    "        return tf.constant(0.0)  # Or another appropriate default value\n",
    "\n",
    "    sorted_tensor = tf.sort(tensor)\n",
    "    middle = n // 2\n",
    "\n",
    "    if n % 2 == 0:\n",
    "        median = (sorted_tensor[middle - 1] + sorted_tensor[middle]) / 2.0\n",
    "    else:\n",
    "        median = sorted_tensor[middle]\n",
    "    \n",
    "    return median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62026c08-982e-4867-8281-d60933483e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_1st_quartile(tensor):\n",
    "   \n",
    "    sorted_tensor = tf.sort(tensor)\n",
    "    k = tf.cast(0.25 * tf.cast(tf.shape(sorted_tensor)[0], tf.float32), tf.int32)\n",
    "    first_quartile = tf.gather(sorted_tensor, k)\n",
    "    \n",
    "    return first_quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c43ba0-2073-418e-b0c7-be398e48a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_3rd_quartile(tensor):\n",
    "   \n",
    "    sorted_tensor = tf.sort(tensor)\n",
    "    k = tf.cast(0.75 * tf.cast(tf.shape(sorted_tensor)[0], tf.float32), tf.int32)\n",
    "    third_quartile = tf.gather(sorted_tensor, k)\n",
    "    \n",
    "    return third_quartile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a5b5b-1457-4cc4-ae04-7885de2024d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, training_data, validation_data, model, loss_func, optimizer, grouping_method, training_step):\n",
    "    \n",
    "    log_dir = f\"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/runs/{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
    "    writer = tf.summary.create_file_writer(log_dir)\n",
    "    \n",
    "    print(\"Training Starting...\")\n",
    "    \n",
    "    for epoch in range(0,epochs):\n",
    "        \n",
    "        training_loss, epoch_predictions, epoch_ground_truth = train_step(model, training_data, loss_func, optimizer, training_step)\n",
    "        \n",
    "        training_acc, train_sim_distance, train_dissim_distance, threshold = compute_eval_metrics(epoch_predictions,\n",
    "                                                                                                  epoch_ground_truth,\n",
    "                                                                                                  epoch,\n",
    "                                                                                                  grouping_method,\n",
    "                                                                                                  writer)\n",
    "        \n",
    "        valid_acc, valid_loss, valid_sim_distance, valid_dissim_distance = test(validation_data, model,\n",
    "                                                                                epoch, loss_func,\n",
    "                                                                                threshold, writer,\n",
    "                                                                                grouping_method)\n",
    "\n",
    "        print(f\"Threshold Determined by {grouping_method}: {threshold} \")\n",
    "        print(f\"EPOCH {epoch+1}/{epochs} - training accuracy: {training_acc:.2f} training loss: {training_loss:.2f} validation accuracy: {valid_acc:.2f} validation_loss: {valid_loss:.2f}\")\n",
    "        print(\"\")\n",
    "\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('train_loss', training_loss, step=epoch)\n",
    "            tf.summary.scalar('train_acc', training_acc, step=epoch)\n",
    "            tf.summary.scalar('valid_loss', valid_loss, step=epoch)\n",
    "            tf.summary.scalar('valid_accuracy', valid_acc, step=epoch)\n",
    "\n",
    "        with writer.as_default():\n",
    "            tf.summary.text(\"Training Epoch Sim Logs \",\n",
    "                            f\"Epoch: {epoch} Sim: {train_sim_distance:.2f}  Dissim: {train_dissim_distance:.2f}\",\n",
    "                            step=epoch)\n",
    "\n",
    "        with writer.as_default():\n",
    "            tf.summary.text(\"Validation Epoch Sim Logs \",\n",
    "                            f\"Epoch: {epoch} Sim: {valid_sim_distance:.2f}  Dissim: {valid_dissim_distance:.2f}\",\n",
    "                            step=epoch)\n",
    "\n",
    "    return model, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255818b1-44e8-48e6-913a-3adb98102030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, training_data, loss_func, optimizer, training_step):\n",
    "\n",
    "    batch_losses, batch_predictions, batch_ground_truth = [], [], []\n",
    "\n",
    "    for i,batch in enumerate(training_data):\n",
    "\n",
    "        batch_doublet=batch[0]\n",
    "        batch_y_true=batch[1]\n",
    "        \n",
    "        batch_loss, batch_y_pred = forward_back_propagation(batch_doublet, batch_y_true, model, loss_func, optimizer)\n",
    "        # batch_y_pred = tf.expand_dims(batch_y_pred, axis=-1)\n",
    "\n",
    "        tf.debugging.assert_equal(tf.shape(batch_y_true), tf.shape(batch_y_pred), message=\"Shape mismatch between true and predicted labels!\")\n",
    "\n",
    "\n",
    "        batch_losses.append(batch_loss)\n",
    "        batch_predictions.append(batch_y_pred)\n",
    "        batch_ground_truth.append(batch_y_true)\n",
    "\n",
    "        print(f\"\\rStep {i+1}/{training_step}  \", end='', flush=True)\n",
    "        \n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "\n",
    "    return epoch_loss, batch_predictions, batch_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d74831-a8e6-4256-be77-4bc9455d9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eval_metrics(epoch_predictions, epoch_ground_truth, epoch, grouping_method, writer):\n",
    "\n",
    "    batch_accuraccys = []\n",
    "\n",
    "    epoch_train_sim_distances = []\n",
    "    epoch_train_dissim_distances = []\n",
    "    \n",
    "    epoch_grouped_similar_distances, epoch_grouped_dissimilar_distances = compute_epoch_threshold(epoch_predictions,\n",
    "                                                                                                  epoch_ground_truth,\n",
    "                                                                                                  grouping_method)\n",
    "    \n",
    "    threshold = epoch_grouped_similar_distances #To change between  epoch_grouped_similar_distances and epoch_grouped_dissimilar_distances for Quartil\n",
    "    \n",
    "    for i, (batch_prediction, batch_ground_truth) in enumerate(zip(epoch_predictions,epoch_ground_truth)):\n",
    "\n",
    "        tf.debugging.assert_equal(tf.shape(batch_ground_truth), tf.shape(batch_prediction), message=\"Shape mismatch between true and predicted labels!\")\n",
    "\n",
    "        batch_grouped_similar_distance, batched_grouped_dissimilar_distance = find_batch_sim_metrics(batch_ground_truth,\n",
    "                                                                                                     batch_prediction,\n",
    "                                                                                                     grouping_method)\n",
    "        \n",
    "        batch_accuracy, batch_similar_correct, batch_dissimilar_correct, batch_total_similar, batch_total_dissimilar=custom_accuracy(batch_ground_truth,\n",
    "                                                                                                                                     batch_prediction,\n",
    "                                                                                                                                     threshold)\n",
    "        with writer.as_default():\n",
    "            tf.summary.text(\"Training Logs\",\n",
    "                            f\"Epoch: {epoch} Batch:{i} Acc: {batch_accuracy:.4f} \"\n",
    "                            f\"Batch Threshold: {threshold:.4f} \"\n",
    "                            f\"Correct sim: {batch_similar_correct}/{batch_total_similar} \"\n",
    "                            f\"Correct dissimilar: {batch_dissimilar_correct}/{batch_total_dissimilar} \"\n",
    "                            f\"{grouping_method} similiar distance: {batch_grouped_similar_distance:.4f} \"\n",
    "                            f\"{grouping_method} dissimiliar distance: {batched_grouped_dissimilar_distance:.4f} \",\n",
    "                            step=i)\n",
    "            \n",
    "        batch_accuraccys.append(batch_accuracy)\n",
    "        epoch_train_sim_distances.append(batch_grouped_similar_distance)\n",
    "        epoch_train_dissim_distances.append(batched_grouped_dissimilar_distance)\n",
    "        \n",
    "    epoch_training_accuraccy = np.mean(batch_accuraccys)\n",
    "    epoch_train_sim_distance = np.mean(epoch_train_sim_distances)\n",
    "    epoch_train_dissim_distance = np.mean(epoch_train_dissim_distances)\n",
    "\n",
    "    return epoch_training_accuraccy, epoch_train_sim_distance, epoch_train_dissim_distance, threshold\n",
    "        \n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25346d29-817e-45b1-9473-a8725ff60683",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_epoch_threshold(epoch_predictions, epoch_ground_truth, grouping_method):\n",
    "\n",
    "    grouped_similar_distances, grouped_dissimilar_distances = [], []\n",
    "    \n",
    "    for i, (batch_prediction, batch_ground_truth) in enumerate(zip(epoch_predictions,epoch_ground_truth)):\n",
    "\n",
    "        tf.debugging.assert_equal(tf.shape(batch_ground_truth), tf.shape(batch_prediction), message=\"Shape mismatch between true and predicted labels!\")\n",
    "\n",
    "        batch_grouped_similar_distance, batched_grouped_dissimilar_distance = find_batch_sim_metrics(batch_ground_truth,\n",
    "                                                                                                     batch_prediction,\n",
    "                                                                                                     grouping_method)\n",
    "        grouped_similar_distances.append(batch_grouped_similar_distance)\n",
    "        grouped_dissimilar_distances.append(batched_grouped_dissimilar_distance)\n",
    "\n",
    "    epoch_grouped_similar_distances = np.mean(grouped_similar_distances)\n",
    "    epoch_grouped_dissimilar_distances = np.mean(grouped_dissimilar_distances)\n",
    "\n",
    "    return epoch_grouped_similar_distances, epoch_grouped_dissimilar_distances\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625a984e-78de-43dd-8be1-e537a160a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(validation_data, model, epoch, loss, threshold, writer, grouping_method):\n",
    "\n",
    "    batch_losses = []\n",
    "    batch_accuraccys = []\n",
    "\n",
    "    epoch_valid_sim_distances = []\n",
    "    epoch_valid_dissim_distances = []\n",
    "    \n",
    "    for i,batch in enumerate(validation_data):\n",
    "\n",
    "        batch_doublet=batch[0]\n",
    "        batch_ground_truth=batch[1]\n",
    "\n",
    "        batch_y_pred = model(batch_doublet, training=False)\n",
    "        # batch_y_pred = tf.expand_dims(batch_y_pred, axis=-1) \n",
    "\n",
    "        tf.debugging.assert_equal(tf.shape(batch_ground_truth), tf.shape(batch_y_pred), message=\"Shape mismatch between true and predicted labels!\")\n",
    "        \n",
    "        batch_loss = loss(batch_ground_truth, batch_y_pred)\n",
    "        \n",
    "\n",
    "        batch_grouped_similar_distance, batch_grouped_dissimilar_distance = find_batch_sim_metrics(batch_ground_truth,\n",
    "                                                                                                   batch_y_pred,\n",
    "                                                                                                   grouping_method)\n",
    "        \n",
    "        batch_valid_acc, batch_similar_correct, batch_dissimilar_correct, batch_total_similar, batch_total_dissimilar = custom_accuracy(batch_ground_truth,\n",
    "                                                                                                                                        batch_y_pred,\n",
    "                                                                                                                                        threshold)\n",
    "        \n",
    "        \n",
    "        with writer.as_default():\n",
    "            tf.summary.text(\"Validation Logs\",\n",
    "                            f\"Epoch: {epoch} Batch:{i} Acc: {batch_valid_acc:.4f} \"\n",
    "                            f\"Correct sim: {batch_similar_correct}/{batch_total_similar} \"\n",
    "                            f\"Correct dissimilar: {batch_dissimilar_correct}/{batch_total_dissimilar} \"\n",
    "                            f\"{grouping_method} similiar distance: {batch_grouped_similar_distance:.4f} \"\n",
    "                            f\"{grouping_method} dissimiliar distance: {batch_grouped_dissimilar_distance:.4f} \",\n",
    "                            step=i)\n",
    "            \n",
    "        batch_accuraccys.append(batch_valid_acc)\n",
    "        batch_losses.append(batch_loss)\n",
    "        \n",
    "        epoch_valid_sim_distances.append(batch_grouped_similar_distance)\n",
    "        epoch_valid_dissim_distances.append(batch_grouped_dissimilar_distance)\n",
    "\n",
    "    epoch_acc = np.mean(batch_accuraccys)\n",
    "    epoch_loss = np.mean(batch_losses)\n",
    "\n",
    "    epoch_sim_distance = np.mean(epoch_valid_sim_distances)\n",
    "    epoch_dissim_distance = np.mean(epoch_valid_dissim_distances)\n",
    "\n",
    "    return epoch_acc, epoch_loss, epoch_sim_distance, epoch_dissim_distance\n",
    "         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
