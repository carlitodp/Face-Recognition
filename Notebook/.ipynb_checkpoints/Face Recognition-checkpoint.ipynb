{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47d6ea0-6418-4404-bb78-1f3ca0866286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 12:17:03.601097: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-19 12:17:03.620203: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-19 12:17:03.626288: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-19 12:17:03.642503: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-19 12:17:04.973454: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n",
      "8\n",
      "3.4.1\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1729358227.327537  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.387440  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.387535  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.390797  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.390895  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.390946  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.516134  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1729358227.516241  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-19 12:17:07.516254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1729358227.516329  317799 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-10-19 12:17:07.516352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9711 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "%run ./Imports_and_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97deee0-3e2a-460e-b109-b6f5d5c64a89",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362937f0-9334-4455-9966-552ebcce7b33",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Triplet Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09482f3f-9617-4181-840e-32ee0e0b1673",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f70ed-3389-415a-943a-1f531cc067f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_random_excluding(input_list, exclude_value):\n",
    "    # Filter the list to exclude the specified value\n",
    "    filtered_list = [item for item in input_list if str(item) != exclude_value]\n",
    "    \n",
    "    # Check if the filtered list is not empty\n",
    "    if not filtered_list:\n",
    "        raise ValueError(\"No valid numbers available in the list after exclusion.\")\n",
    "    \n",
    "    # Pick a random element from the filtered list\n",
    "    return random.choice(filtered_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039c4bb-2572-4c9c-bb89-6de528568480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_path):\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "    img = img.astype(np.float32)\n",
    "    # img = img / 255.0\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8a39-99cb-4773-9948-2bdce90eb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    dataset_path = \"/mnt/c/users/charl/Desktop/Celebrity Faces Dataset\"\n",
    "    celeb_list = os.listdir(dataset_path)\n",
    "    \n",
    "    anch = []\n",
    "    pos = []\n",
    "    neg = []\n",
    "    triplet = []\n",
    "    \n",
    "    for celeb in celeb_list:\n",
    "        image_celeb_list = glob.glob(os.path.join(dataset_path, celeb,\"*.jpg\"))\n",
    "    \n",
    "        for image_celeb in image_celeb_list:\n",
    "            anch.append(process_file(image_celeb))\n",
    "            pos.append(process_file(pick_random_excluding(image_celeb_list,image_celeb)))\n",
    "    \n",
    "            celeb_neg = pick_random_excluding(celeb_list,celeb)\n",
    "            image_celeb_neg_list = glob.glob(os.path.join(dataset_path, celeb_neg,\"*.jpg\"))\n",
    "    \n",
    "            neg.append(process_file(pick_random_excluding(image_celeb_neg_list,image_celeb)))\n",
    "\n",
    "    anch, pos, neg = anch[0:128], pos[0:128], neg[0:128]\n",
    "\n",
    "    for i in range(0, 128):\n",
    "        triplet.append([anch[i], pos[i], neg[i]])\n",
    "        \n",
    "    return tf.convert_to_tensor(triplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d3b0f3-9600-49c9-813c-e631202235b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    for triplet in triplets:\n",
    "        yield (triplet[0], triplet[1], triplet[2]), 0.0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf6d29-290d-4794-9607-cb7f47f578c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = build_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b80e62-363d-46ff-b2be-69bd7b4fc586",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "    build_generator,\n",
    "    output_signature=(\n",
    "        (\n",
    "            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32)\n",
    "        ),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "    )\n",
    ")\n",
    "dataset = dataset.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e306d58d-8912-4706-8d7a-5d310658d305",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf332cf6-3a29-4404-ac20-759f9495d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    # Unpack the embeddings\n",
    "    anchor, positive, negative = tf.split(y_pred, num_or_size_splits=3, axis=1)\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)  # Distance between anchor and positive\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)  # Distance between anchor and negative\n",
    "    \n",
    "    # Compute the triplet loss\n",
    "    loss = tf.maximum(pos_dist - neg_dist + 0.2, 0.0)  # Margin of 0.2\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc2b04-e11d-49f2-b701-47d4c5ca3f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Res = resnet.ResNet50(include_top = False,\n",
    "                      weights = None,\n",
    "                      input_shape=(224,224,3))\n",
    "Res.trainable = True\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(Res.output)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(128)(x)\n",
    "base_res = Model(inputs = Res.input, outputs = x, name = \"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a0672f-b313-4e0e-8656-69e07022ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.keras.Input(shape = (224,224,3), name = \"anchor\")\n",
    "positive = tf.keras.Input(shape = (224,224,3), name = \"positive\")\n",
    "negative = tf.keras.Input(shape = (224,224,3), name = \"negative\")\n",
    "\n",
    "input = [anchor, positive, negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c3242-56d9-4123-8d80-d8a9b9820b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_emb = base_res(anchor)\n",
    "positive_emb = base_res(positive)\n",
    "negative_emb = base_res(negative)\n",
    "\n",
    "output = tf.keras.layers.Concatenate()([anchor_emb, positive_emb, negative_emb])\n",
    "# output = [anchor_emb, positive_emb, negative_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198c229-ef6b-4c93-bcbf-2409e6162e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = Model(inputs=input, outputs=output, name=\"SIAMESE\")\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23317f22-d327-4008-8720-4bf58d78ac25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "siamese_network.compile(optimizer = \"adam\",\n",
    "                         loss = triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89238dc0-b849-4c8d-a9d8-4a03eaaac65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.config.disable_traceback_filtering()\n",
    "siamese_network.fit(dataset, epochs=10, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4072a9-203c-4502-9a48-0e7cbd4f4692",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da01583-b5c7-46e2-bb24-f9ed493199e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_path = \"/mnt/c/users/charl/Desktop/Celebrity Faces Dataset/Denzel Washington/018_e4ed6557.jpg\"\n",
    "positive = \"/mnt/c/users/charl/Desktop/test/denzel_washington_test.jpg\"\n",
    "negative = \"/mnt/c/users/charl/Desktop/test/jamie_foxx_test.jpg\"\n",
    "\n",
    "test_a = process_file(anchor_path)\n",
    "test_a = tf.convert_to_tensor(test_a)\n",
    "test_a = tf.expand_dims(test_a, axis = 0)\n",
    "\n",
    "test_p = process_file(positive)\n",
    "test_p = tf.convert_to_tensor(test_p)\n",
    "test_p = tf.expand_dims(test_p, axis = 0)\n",
    "\n",
    "test_n = process_file(negative)\n",
    "test_n = tf.convert_to_tensor(test_n)\n",
    "test_n = tf.expand_dims(test_n, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b378c-c361-4871-b821-2dacdf07e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = siamese_network.predict([test_a, test_p, test_n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a599665f-fa97-4b6d-8e43-d8b754a2bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2dc535-0feb-4cac-b7f8-713cf0942d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_a, pred_p, pred_n = tf.split(embedding, num_or_size_splits=3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438dbfc1-cacc-46ea-b516-3e9144d47723",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_pos = np.linalg.norm(pred_a - pred_p)\n",
    "anchor_neg = np.linalg.norm(pred_a - pred_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1333653-16bb-49ad-8f6f-689905e95423",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e502b5f-b0e1-486f-9b99-5acb6edd0d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29d5364-ee19-4bfb-9c2a-57b846315655",
   "metadata": {},
   "source": [
    "## Contrastive loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b810ad9b-8394-4219-9dea-e35c39b60e05",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ac51e-93b8-484a-9534-79502407a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images_data(\"CelebrityFaces\")\n",
    "count_images_data(\"FootballFaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0e7766-ed1a-4a74-bbff-4ec190051e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shuffled\n"
     ]
    }
   ],
   "source": [
    "image_shape = (75, 75, 3)\n",
    "batch_size = 64\n",
    "id = datetime.now()\n",
    "\n",
    "# double_p_train = create_double_pos_v2(folder_name=\"CelebrityFaces\",\n",
    "#                                       set_=\"train\",\n",
    "#                                       save_data=True,\n",
    "#                                       id=id,\n",
    "#                                       count_per_image=25,\n",
    "#                                       apply_augmentation=True)\n",
    "\n",
    "# double_n_train = create_double_neg_v2(folder_name=\"CelebrityFaces\",\n",
    "#                                       set_=\"train\",\n",
    "#                                       save_data=True,\n",
    "#                                       id=id,\n",
    "#                                       count_per_image=25,\n",
    "#                                       apply_augmentation=True)\n",
    "\n",
    "double_p_train, double_n_train = load_dataset_from_dir(\"2024_10_17_22_28\", \"train\")\n",
    "\n",
    "buffer_size = len(double_n_train)\n",
    "\n",
    "y_pos = tf.zeros((len(double_p_train),1))\n",
    "y_neg =  tf.ones((len(double_n_train),1))\n",
    "\n",
    "doubles_train = tf.concat([double_p_train, double_n_train], axis=0)\n",
    "ys_train = tf.concat([y_pos, y_neg], axis = 0)\n",
    "\n",
    "step = math.ceil(doubles_train.numpy().shape[0]/batch_size)\n",
    "\n",
    "doubles_train, ys_train = memory_eff_shuffling(doubles_train, ys_train)\n",
    "\n",
    "dataset_train = create_dataset_v2(doubles_train, ys_train, image_shape, \"train\",batch_size, buffer_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e9d28-a4a5-42fe-a1ee-1fb7223e3781",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9539a-0a9a-4a6f-910e-9f280aace987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ShowRandomDoublet(dataset_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a92c1541-758d-4d6c-84d0-cacb9329579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# double_p_valid = create_double_pos_v2(folder_name=\"FootballFaces\",\n",
    "#                                       set_=\"test\",\n",
    "#                                       save_data=True,\n",
    "#                                       id=id,\n",
    "#                                       count_per_image=2,\n",
    "#                                       apply_augmentation=False)\n",
    "\n",
    "# double_n_valid = create_double_neg_v2(folder_name=\"FootballFaces\",\n",
    "#                                       set_=\"test\",\n",
    "#                                       save_data=True,\n",
    "#                                       id=id,\n",
    "#                                       count_per_image=2,\n",
    "#                                       apply_augmentation=False)\n",
    "\n",
    "double_p_valid, double_n_valid = load_dataset_from_dir(\"2024_10_17_22_28\", \"test\")\n",
    "\n",
    "y_pos = tf.zeros((len(double_p_valid),1))\n",
    "y_neg =  tf.ones((len(double_n_valid),1))\n",
    "\n",
    "doubles_valid = tf.concat([double_p_valid, double_n_valid], axis=0)\n",
    "ys_valid = tf.concat([y_pos, y_neg], axis = 0)\n",
    "\n",
    "doubles_valid, ys_valid = memory_eff_shuffling(doubles_valid, ys_valid)\n",
    "\n",
    "dataset_valid = create_dataset_v2(doubles_valid, ys_valid, image_shape, \"valid\",batch_size, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c76cc1-9e04-47f3-8516-6d1716f17e86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ShowRandomDoublet(dataset_valid,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d08611-8572-4b1f-a00d-356ae54ec456",
   "metadata": {},
   "outputs": [],
   "source": [
    "doubles_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e2f470-6aa5-4906-8e96-1140913d6394",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28034d76-b6fe-4db5-8089-88020fcafb31",
   "metadata": {},
   "source": [
    "#### Simple Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd121062-b418-4baf-aaed-f8ac21804b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = regularizers.l2(0.08)\n",
    "\n",
    "input_emb = tf.keras.Input(shape=image_shape)\n",
    "  \n",
    "x = tf.keras.layers.Conv2D(64, (11,11), activation=\"relu\", padding = \"same\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(input_emb)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(128, (7,7), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(256, (4,4), activation=\"relu\", padding=\"same\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(832, activation = \"relu\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(576, activation = \"relu\", kernel_regularizer=l2_reg, kernel_initializer=HeNormal())(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "output = tf.keras.layers.Dense(512, kernel_regularizer=l2_reg, kernel_initializer=GlorotUniform())(x)\n",
    "output = tf.keras.layers.Lambda(lambda output: tf.math.l2_normalize(output, axis=-1))(output)\n",
    "\n",
    "base_model = Model(inputs=input_emb, outputs=output, name=\"embedding\")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef21647b-73bb-4c61-9933-63c3b9792a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_embedding_in = tf.keras.Input(shape = image_shape)\n",
    "second_embedding_in = tf.keras.Input(shape = image_shape)\n",
    "input_list = [first_embedding_in, second_embedding_in]\n",
    "\n",
    "first_embedding = base_model(first_embedding_in)\n",
    "second_embedding = base_model(second_embedding_in)\n",
    "\n",
    "output = tf.keras.layers.Lambda(cosine_distance)([first_embedding, second_embedding])\n",
    "\n",
    "siamese_network = Model(inputs = input_list, outputs=output, name = \"siamese_network\")\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b59394-45d9-40e8-bea8-0a910e524474",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/CelebrityFaces\"\n",
    "anchor, positif, negatif = generate_triplet_string(dataset_path)\n",
    "\n",
    "generate_distance_embbedding(anchor=anchor,\n",
    "                             positif=positif,\n",
    "                             negatif=negatif,\n",
    "                             embedding_model=base_model,\n",
    "                             distance_calculation = siamese_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fde5afd-540f-49b8-84b7-97230c2d63ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method : mean - median - 3rd_quartile\n",
    "initial_learning_rate = 1e-5\n",
    "decay_rate = 0.92  # You can adjust this\n",
    "\n",
    "# Learning rate schedule: decay every 2 epochs\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=step * 2,  # decay every 2 epochs\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=True  # Ensures it decreases in a step-wise manner\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model, T = fit(epochs = 60,\n",
    "               training_data=dataset_train ,\n",
    "               validation_data=dataset_valid,\n",
    "               model=siamese_network,\n",
    "               loss_func=contrastive_loss,\n",
    "               optimizer=optimizer,\n",
    "               grouping_method=\"median\",\n",
    "               training_step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8170a29b-7d27-48bd-ad23-ba155a488c00",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### MobileNetV3Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bcc31-a1b9-4efc-bd8b-377d068aad3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Large(include_top = False,\n",
    "                              weights = \"imagenet\",\n",
    "                              input_shape=image_shape,\n",
    "                              alpha = 1.0)\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63133c-b187-449d-b702-e7eb79cf6e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "for layer in base_model.layers:\n",
    "    name = layer.name\n",
    "    layers.append(name)\n",
    "\n",
    "pourcentages = [0.1, 0.25, 0.50, 0.70, 0.90]\n",
    "freezing_checkpoints = []\n",
    "\n",
    "for pourcent in pourcentages:\n",
    "    ckpt_index = int(pourcent * len(layers))\n",
    "    ckpt = layers[ckpt_index]\n",
    "    freezing_checkpoints.append(ckpt)\n",
    "\n",
    "freezing_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f13796-400a-4110-9d92-bc72968e6c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set layers to non-trainable up to 'block_6_project_BN'\n",
    "layer_name = 'expanded_conv_1_project'\n",
    "freeze = True\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == layer_name:\n",
    "        print(\"Freezing\")\n",
    "        freeze = False\n",
    "    layer.trainable = not freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa1ceb8-f174-4df1-8d9f-4e8d99072499",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = instanciate_model(base_model=base_model,\n",
    "                                    image_shape=image_shape,\n",
    "                                    apply_reg=True,\n",
    "                                    reg_weight=0.09,\n",
    "                                    apply_dropout=True,\n",
    "                                    dropout_prob=0.3,\n",
    "                                    apply_augmentation=False,\n",
    "                                    augmentation_model=None,\n",
    "                                    distance_method=\"cosine\",\n",
    "                                    embedding = 512)\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3021a4-acff-4b59-bcc6-f8092cd46db3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Method : mean - median - 3rd_quartile\n",
    "initial_learning_rate = 1e-5\n",
    "decay_rate = 0.96  # You can adjust this\n",
    "\n",
    "# Learning rate schedule: decay every 2 epochs\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=step * 2,  # decay every 2 epochs\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=True  # Ensures it decreases in a step-wise manner\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model, T = fit(epochs = 18,\n",
    "               training_data=dataset_train ,\n",
    "               validation_data=dataset_valid,\n",
    "               model=siamese_network,\n",
    "               loss_func=contrastive_loss,\n",
    "               optimizer=optimizer,\n",
    "               grouping_method=\"median\",\n",
    "               training_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcad6928-f0d0-4385-b05a-02ef74f04cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d138a6-eed1-47ab-a897-cc545d9794b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_accuracy(siamese_network, dataset_valid,  0.47)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be1be3-f541-473d-952f-eacdd4dc540f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### MobileNetV3Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d5723-d7a9-42b5-9e69-e7e3a32ae225",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Small(include_top = False,\n",
    "                              weights = \"imagenet\",\n",
    "                              input_shape=image_shape,\n",
    "                              alpha = 1.0)\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57263f1-41d9-4aa6-b09f-40ad2aac6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set layers to non-trainable up to 'block_6_project_BN'\n",
    "layer_name = 'expanded_conv_9_project_bn'\n",
    "freeze = True\n",
    "for layer in base_model.layers:\n",
    "    if layer.name == layer_name:\n",
    "        print(\"Freezing\")\n",
    "        freeze = False\n",
    "    layer.trainable = not freeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf68e18-0051-420d-bc48-e896180bd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = augmentation_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740b8a1-7d3f-4635-9557-2b467f204a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_network = instanciate_model(base_model=base_model,\n",
    "                                    image_shape=image_shape,\n",
    "                                    apply_reg=True,\n",
    "                                    reg_weight=0.01,\n",
    "                                    apply_dropout=True,\n",
    "                                    dropout_prob=0.2,\n",
    "                                    apply_augmentation=False,\n",
    "                                    augmentation_model=None,\n",
    "                                    distance_method=\"cosine\",\n",
    "                                    embedding = 256)\n",
    "siamese_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188b16b-b2b2-4031-8e47-e2a25a43b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method : mean - median - 3rd_quartile\n",
    "initial_learning_rate = 1e-5\n",
    "decay_rate = 0.96  # You can adjust this\n",
    "\n",
    "# Learning rate schedule: decay every 2 epochs\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=step * 2,  # decay every 2 epochs\n",
    "    decay_rate=decay_rate,\n",
    "    staircase=True  # Ensures it decreases in a step-wise manner\n",
    ")\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model, T = fit(epochs = 50,\n",
    "               training_data=dataset_train ,\n",
    "               validation_data=dataset_valid,\n",
    "               model=siamese_network,\n",
    "               loss_func=contrastive_loss,\n",
    "               optimizer=optimizer,\n",
    "               grouping_method=\"median\",\n",
    "               training_step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79360cdb-8b73-4a41-8ab1-c610d784cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = calculate_accuracy(siamese_network, dataset_valid,  0.55)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f5eaa6-5873-4336-9a8e-01fedb95f0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/mnt/c/users/charl/Desktop/Face_Recognition_Siamese/Data/clean/CelebrityFaces\"\n",
    "anchor, positif, negatif = generate_triplet_string(dataset_path)\n",
    "\n",
    "generate_distance_embbedding(anchor=anchor,\n",
    "                             positif=positif,\n",
    "                             negatif=negatif,\n",
    "                             embedding_model=base_model,\n",
    "                             distance_calculation = siamese_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf27bd0-a86c-4004-8706-1ada57799933",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb123f45-7e39-42f9-b97d-d8d19f136c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
